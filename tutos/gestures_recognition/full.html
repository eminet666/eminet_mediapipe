<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Reconnaissance de Gestes</title>
    <style>
        body {
            background-color: #1e1e1e;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: white;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 0; padding: 20px;
        }

        h1 { margin-bottom: 10px; }

        #container {
            position: relative;
            border: 4px solid #00d2ff;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 0 20px rgba(0, 210, 255, 0.3);
        }

        video { display: block; transform: scaleX(-1); /* Effet miroir */ }
        
        /* Le Canvas sert √† dessiner le squelette de la main */
        canvas {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            transform: scaleX(-1); /* Effet miroir aussi */
        }

        /* La zone de texte qui affiche le r√©sultat */
        #gestureOutput {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            padding: 10px 30px;
            border-radius: 50px;
            font-size: 32px;
            font-weight: bold;
            text-transform: uppercase;
            color: #00d2ff;
            border: 2px solid #00d2ff;
            min-width: 200px;
            text-align: center;
        }
    </style>
</head>
<body>

    <h1>‚úåÔ∏è Fais un geste ! ‚úä</h1>
    <p id="status">Chargement du mod√®le...</p>

    <div id="container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="outputCanvas"></canvas>
        <div id="gestureOutput">...</div>
    </div>

    <script type="module">
        import {
            GestureRecognizer,
            FilesetResolver,
            DrawingUtils
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        const video = document.getElementById("webcam");
        const canvas = document.getElementById("outputCanvas");
        const ctx = canvas.getContext("2d");
        const gestureOutput = document.getElementById("gestureOutput");
        const statusText = document.getElementById("status");
        
        let gestureRecognizer = undefined;
        let runningMode = "VIDEO";
        let lastVideoTime = -1;

        // 1. Initialisation du Reconnaisseur
        const createGestureRecognizer = async () => {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );

            gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "gesture_recognizer.task", // Ton fichier t√©l√©charg√©
                    delegate: "GPU"
                },
                runningMode: runningMode,
                numHands: 2 // Peut d√©tecter 2 mains
            });

            statusText.innerText = "‚úÖ Pr√™t ! Active la cam√©ra.";
            startWebcam();
        };

        // 2. D√©marrage Webcam
        function startWebcam() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
            });
        }

        // 3. Boucle de Pr√©diction
        async function predictWebcam() {
            // Ajustement taille canvas
            if (canvas.width !== video.videoWidth) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }

            let startTimeMs = performance.now();

            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                
                // --- L'APPEL MAGIQUE ---
                const results = gestureRecognizer.recognizeForVideo(video, startTimeMs);

                // Nettoyage du canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (results.landmarks) {
                    // A. On dessine les points (Feedback visuel)
                    const drawingUtils = new DrawingUtils(ctx);
                    for (const landmarks of results.landmarks) {
                        drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 3 });
                        drawingUtils.drawLandmarks(landmarks, { color: "#FF0000", lineWidth: 1 });
                    }

                    // B. On affiche le TEXTE du geste
                    if (results.gestures.length > 0) {
                        // L'IA nous donne : categoryName (Nom) et score (Confiance)
                        const categoryName = results.gestures[0][0].categoryName;
                        const score = parseFloat(results.gestures[0][0].score * 100).toFixed(0);
                        
                        // Si le score est bon, on affiche
                        if (score > 50) {
                            gestureOutput.innerText = `${categoryName} ${emojiMap(categoryName)}`;
                        }
                    } else {
                        gestureOutput.innerText = "Aucune main";
                    }
                }
            }
            window.requestAnimationFrame(predictWebcam);
        }

        // Petit utilitaire pour mettre des √©mojis sympas
        function emojiMap(gestureName) {
            const map = {
                "Closed_Fist": "‚úä",
                "Open_Palm": "‚úã",
                "Pointing_Up": "‚òùÔ∏è",
                "Thumb_Down": "üëé",
                "Thumb_Up": "üëç",
                "Victory": "‚úåÔ∏è",
                "ILoveYou": "ü§ü",
                "None": ""
            };
            return map[gestureName] || "";
        }

        createGestureRecognizer();
    </script>
</body>
</html>